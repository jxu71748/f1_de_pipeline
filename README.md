# Formula 1 Data Pipeline Project 🏎️ 🏎️ 🏎️ 

## Project Objective
This project is part of the DE Zoomcamp course final project. The goal is to build a complete batch data pipeline using GCP, Terraform, Airflow, and Spark. The dataset is from Kaggle and contains Formula 1 race data from 1950 to 2024.

## Tools Used
- Cloud: Google Cloud Platform (GCS & BigQuery)
- Infrastructure as code (IaC): Terraform
- Workflow orchestration: Airflow
- Batch processing: PySpark for data transformation
- Visualization: Google Data Studio
- Python for scripting (data download, upload, transformation)

## Current Progress
- ✅ Downloaded raw data from Kaggle
- ✅ Created GCS bucket and BigQuery dataset using Terraform
- 🔜 Upload raw CSV files to GCS via Python
- 🔜 Build Airflow DAGs for ingestion and transformation
- 🔜 Create a dashboard with race results insights

## Folder Structure

